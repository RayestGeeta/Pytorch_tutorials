{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.Tensor([[1,2,3],[4,5,6]]) # list -> torch\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()  # torch -> list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()   # the shape of tensor\n",
    "print(a.shape)\n",
    "a.numel()  # the total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 2.0, 3.0], [4.0, 5.0, 6.0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.Tensor(((1,2,3),(4,5,6)))  # tuple -> tensor\n",
    "tuple(b.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]]) \t tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]]) \t tensor([ 0.,  3.,  6.,  9.]) \t tensor([  0.,   6.,  12.])\n"
     ]
    }
   ],
   "source": [
    "c = t.ones(2,3)  # create a tensor(size = 2x3) whose elements are all one\n",
    "d = t.zeros(2,3)  # create a tensor whose elements are 0\n",
    "e = t.arange(0,12,3)  # create a tensor(size = n*1) which is within a range of 0 to 11 and a distance of 3\n",
    "f = t.linspace(0,12,3)  # create a tensor(size = n*1) which is within a range of 0 to 11 and divided into 3 parts\n",
    "print(c,'\\t', d, '\\t', e, '\\t', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8974,  0.4957,  0.8911],\n",
      "        [ 0.7395,  0.9890,  0.5776]]) tensor([[ 1.3443, -0.8971,  0.3569],\n",
      "        [-0.3426, -1.9804, -0.0482]]) tensor([ 2.0464]) tensor([ 9,  6,  0,  8,  7,  1,  2,  3,  5,  4])\n"
     ]
    }
   ],
   "source": [
    "g = t.rand(2,3)  # the tensor is within -1 to 1 and is uniform distribution\n",
    "h = t.randn(2,3)  # which is standard distribution\n",
    "i = t.normal(t.Tensor((1,)),t.Tensor((1,)))  # mean = 1 ,std = 1,i is a random number which is normal state form them\n",
    "j = t.randperm(10)  # it is random order for 0 to 9\n",
    "print(g, h, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.]), tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(6)\n",
    "b = a.view(2,3)\n",
    "a,b  # a and b are share the same space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(-1, 3)  # if a size == -1,tensor will automaticly calculate.\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.unsqueeze(0)   # it will add a dimension in subscript which is 0\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c.squeeze(0)   # it will compress a dimension in subscript = 0   squeeze only can compress the dimension = 1\n",
    "c.squeeze()  # the dimenson which is 1  will be all compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust the size \n",
    "c = b.reshape(1,6)  # resize()  resize_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  2.0000],\n",
       "        [ 3.0000,  4.0000,  5.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if reshaped size is beyond the data.It will be distrubuted new space.\n",
    "b.resize_(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 3.,  4.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch supposes the normal indexes.\n",
    "b[:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1],\n",
       "        [ 1,  1,  1],\n",
       "        [ 0,  0,  0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b>1  # it will return a bytetensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  3.,  4.,  5.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[b>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.Tensor([[1,2,3,4]])\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   2.,   3.],\n",
       "        [  4.,   5.,   6.,   7.],\n",
       "        [  8.,   9.,  10.,  11.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0,12).reshape(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.],\n",
      "        [ 5.],\n",
      "        [ 9.]]) tensor([  8.,   9.,  10.,  11.]) tensor([[ 0,  1],\n",
      "        [ 0,  2],\n",
      "        [ 0,  3],\n",
      "        [ 1,  0],\n",
      "        [ 1,  1],\n",
      "        [ 1,  2],\n",
      "        [ 1,  3],\n",
      "        [ 2,  0],\n",
      "        [ 2,  1],\n",
      "        [ 2,  2],\n",
      "        [ 2,  3]]) tensor([[ 0.,  1.,  2.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "# some examples about the choosed functions\n",
    "b = t.index_select(a,1,t.LongTensor((1,)))\n",
    "c = t.masked_select(a,a>7)\n",
    "d = t.nonzero(a)  #return the elements's subscript which is not zero\n",
    "f = a.gather(0, t.LongTensor([[0,0,0,0]]))  # index needs to have the same dimensions with the tensor\n",
    "print(b,c,d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   4.,   8.],\n",
       "        [  1.,   5.,   9.],\n",
       "        [  2.,   6.,  10.],\n",
       "        [  3.,   7.,  11.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = a.t()  # a's transposition\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  9.,  10.,  11.],\n",
       "         [ 12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.]],\n",
       "\n",
       "        [[ 18.,  19.,  20.],\n",
       "         [ 21.,  22.,  23.],\n",
       "         [ 24.,  25.,  26.]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0,27).view(3,3,3)\n",
    "x[[1,0],[1,2],[1,2]]  # index the (1,1,1) and (0,2,2)\n",
    "x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.],\n",
       "         [  3.,   4.,   5.],\n",
       "         [  6.,   7.,   8.]],\n",
       "\n",
       "        [[  9.,  10.,  11.],\n",
       "         [ 12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.]],\n",
       "\n",
       "        [[ 18.,  19.,  20.],\n",
       "         [ 21.,  22.,  23.],\n",
       "         [ 24.,  25.,  26.]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type()\n",
    "x = x.int()  # translate the float to int(double,byte,char,short,Long)\n",
    "x.type(t.FloatTensor)\n",
    "x.type()\n",
    "x.type_as(a)  # make x.type  =  a.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.new(2,3)  # x.type = y.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000,  0.5403, -0.4161],\n",
      "         [-0.9900, -0.6536,  0.2837],\n",
      "         [ 0.9602,  0.7539, -0.1455]],\n",
      "\n",
      "        [[-0.9111, -0.8391,  0.0044],\n",
      "         [ 0.8439,  0.9074,  0.1367],\n",
      "         [-0.7597, -0.9577, -0.2752]],\n",
      "\n",
      "        [[ 0.6603,  0.9887,  0.4081],\n",
      "         [-0.5477, -1.0000, -0.5328],\n",
      "         [ 0.4242,  0.9912,  0.6469]]])\n",
      "tensor([[[  0.,   1.,   2.],\n",
      "         [  3.,   4.,   5.],\n",
      "         [  6.,   7.,   8.]],\n",
      "\n",
      "        [[  9.,  10.,  11.],\n",
      "         [ 12.,  13.,  14.],\n",
      "         [ 15.,  16.,  17.]],\n",
      "\n",
      "        [[ 18.,  19.,  20.],\n",
      "         [ 21.,  22.,  23.],\n",
      "         [ 24.,  25.,  26.]]])\n"
     ]
    }
   ],
   "source": [
    "# elements-wise\n",
    "x = t.arange(0,27).reshape(3,3,3)\n",
    "print(t.cos(x))\n",
    "t.clamp(x,1,4)  #if x[i]<1 : x[i]=1;else x[i]>4:x[i]=4\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.,   4.,   5.],\n",
       "        [ 12.,  13.,  14.],\n",
       "        [ 21.,  22.,  23.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge operation :mean/sum/median/mode   norm/dist std/var  cumsum/cumprod\n",
    "x1 = x.mean(dim = 1)  # x1[0][0] = dum(x[0][i][0])/3  i=[0,1,2]\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2.,   5.,   8.],\n",
       "         [ 11.,  14.,  17.],\n",
       "         [ 20.,  23.,  26.]]), tensor([[ 2,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         [ 2,  2,  2]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(x,dim=2)  # first tensor stands for the max. second stands for the subcript which corresponds with the max one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.t()  # translation will result to the space which isn't is continuous\n",
    "y.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.contiguous()\n",
    "y.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]] tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5]], dtype=torch.int32) [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[1 1]\n",
      " [2 3]\n",
      " [4 5]] tensor([[ 1,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5]], dtype=torch.int32) [[1 1]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "a = np.arange(0,6).reshape(3,2)\n",
    "b = t.from_numpy(a)   # t.Tensor(a)\n",
    "c = b.numpy()\n",
    "print(a, b, c)\n",
    "a[0,0] = 1\n",
    "print(a, b, c)   # a,b and c share the same space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   2.],\n",
       "         [  4.,   6.],\n",
       "         [  8.,  10.]],\n",
       "\n",
       "        [[  7.,   8.],\n",
       "         [ 10.,  12.],\n",
       "         [ 14.,  16.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = t.arange(0,12).reshape(2,3,2)\n",
    "b.unsqueeze(0).expand(2,3,2).type(t.FloatTensor)+d  #Broadcast:unsqueeze,expand and expand doesn't add the sapce\n",
    "b.float()+d  # pytorch can carry out broadcast automaticly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      "[torch.FloatStorage of size 6]  0.0\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      "[torch.FloatStorage of size 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tensor includes the Tensor(size,stride,type) and the Storage(data,space)\n",
    "a = t.arange(0,6).reshape(2,3)\n",
    "a.storage(),id(a.storage()),id(a)\n",
    "# This operation is like the c language's points.\n",
    "c = a[0,1]\n",
    "print(c.storage(),a.storage())  #their storages are the same.\n",
    "d = t.Tensor(a.storage())\n",
    "id(a.storage()) == id(b.storage()) == id(c.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(a,'a.pth')  # save a tensor as a finder(pth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]]), tensor([[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.load('a.pth')  # reload a tensor\n",
    "b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.60 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "22.6 µs ± 17 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.96 ms ± 175 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = t.zeros(100)\n",
    "y = t.ones(100)\n",
    "%timeit -n 10 x+y  # using the vector can save more time.\n",
    "%timeit -n 100 for i,j in zip(x,y): i+j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEqpJREFUeJzt3XGMnHd95/H3p7bTLgRqWm847Hhr0gMfvZTGsEQ5olIaaJ0ilPiq41quRNaVwypCvYRL3WKQjkO601GMgmhVVYrqNPkjTZs2xlToqImiHDTSxciOHRyzdaP2KM3aR5KjJumxDXb43h/zOLE3a8/MemZn9vH7JVk7+3ueWX+0lj/77G9+83tSVUiSlr8fGHUASdJgWOiS1BIWuiS1hIUuSS1hoUtSS1joktQSFroktUTXQk/yQ0m+muTRJEeSfKIZf22SfUkeT/InSS4ZflxJ0rn0coX+HHBdVf0UcBVwfZJrgN8GPlNVrwP+AXj/8GJKkrpZ2e2E6ryV9B+bT1c1fwq4Dvh3zfhdwH8Bfv98X2vNmjW1YcOGRUaVpIvTgQMHnq6qyW7ndS10gCQrgAPAPwd+D/gb4ERVnWpOeQJYd47nbgO2AUxNTbF///5e/kpJUiPJ3/VyXk8vilbV81V1FXA5cDXwhoVOO8dzb6+q6aqanpzs+gNGkrRIfa1yqaoTwP8ErgFWJzl9hX85cGyw0SRJ/ehllctkktXN4wngncAM8CDwb5rTtgKfH1ZISVJ3vcyhvwa4q5lH/wHg3qr6QpKvA3+c5L8CB4FdQ8wpSeqil1UuXwM2LTD+t3Tm0yVJY6CnVS6SpBftOTjLzr1HOXZijrWrJ9i+eSNbNi240G9JWeiS1Ic9B2fZsfswcyefB2D2xBw7dh8GGHmpu5eLJPVh596jL5T5aXMnn2fn3qMjSvQiC12S+nDsxFxf40vJQpekPqxdPdHX+FKy0CWpD9s3b2Ri1YqzxiZWrWD75o0jSvQiXxSVpD6cfuHTVS6S1AJbNq0biwKfzykXSWoJC12SWsJCl6SWsNAlqSUsdElqCVe5SNKQLPUmXha6JA3BKDbxcspFkoZgFJt4WeiSNASj2MTLQpekIRjFJl693CR6fZIHk8wkOZLk5mb8qiQPJzmUZH8Sb0cnSY1RbOLVy4uip4Bbq+qRJK8ADiS5H/gU8Imq+mKSdzWfv31oSSVpGRnFJl693CT6OHC8efxskhlgHVDAK5vTfhg4NqyQkrQcLfUmXn0tW0yyAdgE7ANuAfYm+TSdqZu3nuM524BtAFNTUxcQVZJ0Pj2/KJrkUuA+4Jaqegb4IPDhqloPfBjYtdDzqur2qpququnJyclBZJYkLaCnQk+yik6Z311Vu5vhrcDpx38K+KKoJI1QL6tcQufqe6aqbjvj0DHgZ5rH1wGPDz6eJKlXvcyhXwvcBBxOcqgZ+yjwAeCzSVYC/0QzTy5JGo1eVrk8BOQch9882DiSpMXynaKS1BIWuiS1hIUuSS1hoUtSS1joktQSFroktYSFLkktYaFLUktY6JLUEha6JLWEhS5JLWGhS1JLWOiS1BIWuiS1hIUuSS1hoUtSS1joktQSFroktUQvN4len+TBJDNJjiS5+Yxjv57kaDP+qeFGlSSdTy83iT4F3FpVjyR5BXAgyf3Aq4EbgTdW1XNJLhtmUEnS+fVyk+jjwPHm8bNJZoB1wAeAT1bVc82xJ4cZVJJ0fn3NoSfZAGwC9gGvB346yb4kX07ylsHHkyT1qpcpFwCSXArcB9xSVc8kWQm8CrgGeAtwb5IrqqrmPW8bsA1gampqYMElSWfr6Qo9ySo6ZX53Ve1uhp8AdlfHV4HvA2vmP7eqbq+q6aqanpycHFRuSdI8vaxyCbALmKmq2844tAe4rjnn9cAlwNPDCClJ6q6XKZdrgZuAw0kONWMfBe4A7kjyGPA9YOv86RZJ0tLpZZXLQ0DOcfh9g40jSVos3ykqSS1hoUtSS1joktQSFroktYSFLkktYaFLUktY6JLUEha6JLWEhS5JLWGhS1JLWOiS1BIWuiS1hIUuSS1hoUtSS1joktQSFroktYSFLkktYaFLUkv0cpPo9UkeTDKT5EiSm+cd/40klWTN8GJKkrrp5SbRp4Bbq+qRJK8ADiS5v6q+nmQ98HPAN4eaUpLUVdcr9Ko6XlWPNI+fBWaAdc3hzwC/CdTQEkqSetLXHHqSDcAmYF+SG4DZqnp0CLkkSX3qZcoFgCSXAvcBt9CZhvkY8PM9PG8bsA1gampqcSklSV31dIWeZBWdMr+7qnYDPw68Fng0yTeAy4FHkvyz+c+tqturarqqpicnJweXXJJ0lq5X6EkC7AJmquo2gKo6DFx2xjnfAKar6ukh5ZQkddHLFfq1wE3AdUkONX/eNeRckqQ+db1Cr6qHgHQ5Z8OgAkmSFsd3ikpSS1joktQSFroktYSFLkktYaFLUktY6JLUEha6JLWEhS5JLWGhS1JL9LzbotQ2ew7OsnPvUY6dmGPt6gm2b97Ilk3ruj9RGlMWui5Kew7OsmP3YeZOPg/A7Ik5duw+DGCpa9lyykUXpZ17j75Q5qfNnXyenXuPjiiRdOEsdF2Ujp2Y62tcWg4sdF2U1q6e6GtcWg4sdF2Utm/eyMSqFWeNTaxawfbNG0eUSLpwviiqi9LpFz5d5aI2sdB10dqyaZ0FrlZxykWSWqJroSdZn+TBJDNJjiS5uRnfmeSvknwtyeeSrB5+XEnSufRyhX4KuLWq3gBcA3woyU8A9wNXVtUbgb8GdgwvpiSpm66FXlXHq+qR5vGzwAywrqq+VFWnmtMeBi4fXkxJUjd9zaEn2QBsAvbNO/SrwBcHE0mStBg9r3JJcilwH3BLVT1zxvjH6EzL3H2O520DtgFMTU1dUFhp0NygS23S0xV6klV0yvzuqtp9xvhW4N3Ar1RVLfTcqrq9qqaranpycnIQmaWBOL1B1+yJOYoXN+jac3B21NGkRelllUuAXcBMVd12xvj1wG8BN1TVd4cXURoON+hS2/Qy5XItcBNwOMmhZuyjwO8APwjc3+l8Hq6qXxtKSmkI3KBLbdO10KvqISALHPofg48jLZ21qyeYXaC83aBLy5XvFNVFyw261Dbu5aKLlht0qW0sdF3U3KBLbeKUiyS1hIUuSS1hoUtSS1joktQSFroktYSFLkktYaFLUktY6JLUEha6JLWEhS5JLWGhS1JLWOiS1BIWuiS1hIUuSS1hoUtSS/Ryk+j1SR5MMpPkSJKbm/EfSXJ/ksebj68aflxJ0rn0coV+Cri1qt4AXAN8KMlPAB8BHqiq1wEPNJ9Lkkaka6FX1fGqeqR5/CwwA6wDbgTuak67C9gyrJCSpO76mkNPsgHYBOwDXl1Vx6FT+sBlgw4nSepdz4We5FLgPuCWqnqmj+dtS7I/yf6nnnpqMRklST3oqdCTrKJT5ndX1e5m+FtJXtMcfw3w5ELPrarbq2q6qqYnJycHkVmStIBeVrkE2AXMVNVtZxz6c2Br83gr8PnBx5Mk9WplD+dcC9wEHE5yqBn7KPBJ4N4k7we+CbxnOBElSb3oWuhV9RCQcxx+x2DjSJIWy3eKSlJLWOiS1BIWuiS1hIUuSS1hoUtSS1joktQSFroktYSFLkktYaFLUktY6JLUEha6JLWEhS5JLWGhS1JLWOiS1BIWuiS1hIUuSS1hoUtSS1joktQSvdwk+o4kTyZ57Iyxq5I8nORQkv1Jrh5uTElSN71cod8JXD9v7FPAJ6rqKuA/N59Lkkaoa6FX1VeAb88fBl7ZPP5h4NiAc0mS+rRykc+7Bdib5NN0fii8dXCRJEmLsdhC/yDw4aq6L8m/BXYB71zoxCTbgG0AU1NTi/zrNEx7Ds6yc+9Rjp2YY+3qCbZv3siWTetGHUtSn1JV3U9KNgBfqKorm8+/A6yuqkoS4DtV9crzfAkApqena//+/ReWWAO15+AsO3YfZu7k8y+MTaxawX//xZ+01KUxkeRAVU13O2+xyxaPAT/TPL4OeHyRX0cjtnPv0bPKHGDu5PPs3Ht0RIkkLVbXKZck9wBvB9YkeQL4OPAB4LNJVgL/RDOlouXn2Im5vsYlja+uhV5V7z3HoTcPOItGYO3qCWYXKO+1qydGkEbShfCdohe57Zs3MrFqxVljE6tWsH3zxhElkrRYi13lopY4/cKnq1yk5c9CF1s2rbPApRZwykWSWsJCl6SWsNAlqSUsdElqCQtdklrCVS5LyE2wJA2Thb5E5m+CNXtijh27DwNY6pIGwimXJeImWJKGzUJfIm6CJWnYLPQlcq7NrtwES9KgWOhLxE2wJA2bL4ouETfBkjRsFvoSchMsScPklIsktYSFLkkt0bXQk9yR5Mkkj80b//UkR5McSfKp4UWUJPWilyv0O4HrzxxI8rPAjcAbq+pfAp8efDRJUj+6FnpVfQX49rzhDwKfrKrnmnOeHEI2SVIfFjuH/nrgp5PsS/LlJG8ZZChJUv8Wu2xxJfAq4BrgLcC9Sa6oqpp/YpJtwDaAqampxeaUJHWx2Cv0J4Dd1fFV4PvAmoVOrKrbq2q6qqYnJycXm1OS1MViC30PcB1AktcDlwBPDyqUJKl/XadcktwDvB1Yk+QJ4OPAHcAdzVLG7wFbF5pukSQtna6FXlXvPceh9w04iyTpAvhOUUlqCQtdklrCQpeklmjd9rl7Ds6657iki1KrCn3PwVl27D78ws2YZ0/MsWP3YQBLXVLrtWrKZefeoy+U+WlzJ59n596jI0okSUunVYV+7MRcX+OS1CatKvS1qyf6GpekNmlVoW/fvJGJVSvOGptYtYLtmzeOKJEkLZ1l8aJorytXTo+5ykXSxWjsC73flStbNq2zwCVdlMZ+ysWVK5LUm7EvdFeuSFJvxr7QXbkiSb0Z+0J35Yok9WbsXxR15Yok9WbsCx1cuSJJvRj7KRdJUm+6FnqSO5I82dw/dP6x30hSSdYMJ54kqVe9XKHfCVw/fzDJeuDngG8OOJMkaRG6FnpVfQX49gKHPgP8JlCDDiVJ6t+i5tCT3ADMVtWjA84jSVqkvle5JHkZ8DHg53s8fxuwrfn0H5N0e8/+GuDpfnMtMTMOznLIacbBWA4ZYTxz/lgvJ6Wq+4xJkg3AF6rqyiQ/CTwAfLc5fDlwDLi6qv7PoqKe/Xftr6rpC/06w2TGwVkOOc04GMshIyyfnAvp+wq9qg4Dl53+PMk3gOmqGrefaJJ0Uell2eI9wP8CNiZ5Isn7hx9LktSvrlfoVfXeLsc3DCxNx+0D/nrDYMbBWQ45zTgYyyEjLJ+cL9HTHLokafz51n9JaomxKvQk30hyOMmhJPtHnWchSVYn+bMkf5VkJsm/GnWmMyXZ2Hz/Tv95Jskto841X5IPJzmS5LEk9yT5oVFnmi/JzU2+I+P0PVxoO44kP5Lk/iSPNx9fNYYZ39N8L7+fZOSrSM6RcWfzf/trST6XZPUoM/ZrrAq98bNVddUYLxv6LPAXVfUvgJ8CZkac5yxVdbT5/l0FvJnO8tLPjTjWWZKsA/4jndVRVwIrgF8ebaqzJbkS+ABwNZ1/53cned1oU73gTl66HcdHgAeq6nV0lhV/ZKlDzXMnL834GPCLwFeWPM3C7uSlGe8HrqyqNwJ/DexY6lAXYhwLfWwleSXwNmAXQFV9r6pOjDbVeb0D+Juq+rtRB1nASmAiyUrgZXTeyzBO3gA8XFXfrapTwJeBfz3iTMA5t+O4EbireXwXsGVJQ82zUMaqmqmqsbkZ8Dkyfqn59wZ4mM77bJaNcSv0Ar6U5EDzDtNxcwXwFPCHSQ4m+YMkLx91qPP4ZeCeUYeYr6pmgU/T2djtOPCdqvrSaFO9xGPA25L8aPPu6HcB60ec6XxeXVXHAZqPl3U5X939KvDFUYfox7gV+rVV9SbgF4APJXnbqAPNsxJ4E/D7VbUJ+H+M/lfbBSW5BLgB+NNRZ5mvmd+9EXgtsBZ4eZL3jTbV2apqBvhtOr+C/wXwKHDqvE9SayT5GJ1/77tHnaUfY1XoVXWs+fgknXnfq0eb6CWeAJ6oqn3N539Gp+DH0S8Aj1TVt0YdZAHvBP53VT1VVSeB3cBbR5zpJapqV1W9qareRudX88dHnek8vpXkNQDNxydHnGfZSrIVeDfwK7XM1nWPTaEneXmSV5x+TGfzr5fcVGOUmr1q/j7J6TtUvwP4+ggjnc97GcPplsY3gWuSvCxJ6Hwfx+rFZYAklzUfp+i8mDeu30+APwe2No+3Ap8fYZZlK8n1wG8BN1TVd7udP27G5o1FSa7gxdUYK4E/qqr/NsJIC0pyFfAHwCXA3wL/vqr+YbSpztbM+f49cEVVfWfUeRaS5BPAL9H5tfYg8B+q6rnRpjpbkr8EfhQ4CfynqnpgxJGAF7bjeDudXQG/BXwc2APcC0zR+YH5nqpa6D4Go8z4beB3gUngBHCoqjaPWcYdwA8C/7c57eGq+rWRBFyEsSl0SdKFGZspF0nShbHQJaklLHRJagkLXZJawkKXpJaw0CWpJSx0SWoJC12SWuL/A2TctuCnhsy3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28c81d95eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example: linear regression\n",
    "import matplotlib.pyplot as plt\n",
    "t.manual_seed(1000)  # set up the random seed\n",
    "def get_fake_data(batch_size = 8):\n",
    "    x = t.rand(batch_size, 1)*20\n",
    "    y = x*2 + (1 + t.rand(x.size()))*3  # add the noise error\n",
    "    return x,y\n",
    "x,y = get_fake_data()\n",
    "plt.scatter(x.squeeze().numpy(),y.squeeze().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
